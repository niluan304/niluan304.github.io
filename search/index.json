[{"content":"encoding/json/v2 即将在 go1.25 作为实验特性推出，真的非常让人期待。笔者回顾日常开发中，对 v1(encoding/json) 的使用，顺势总结了一些的技巧，而经过测试，这些技巧在 encoding/json/v2 仍然是有效的，这同样让笔者非常开心。\n关于 v2 的相关介绍，可查看：手把手带你玩转GOEXPERIMENT=jsonv2：Go下一代JSON库初探 | Tony Bai\n基本的序列化和反序列化 先简单回顾下 JSON 这种数据交换格式在 go 中的使用：\ntype User struct { UserId int64 `json:\u0026#34;userId\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` Birthday time.Time `json:\u0026#34;birthday\u0026#34;` } func main() { user := User{ UserId: 20060102150405, Password: \u0026#34;zwei\u0026#34;, Birthday: time.Unix(1136214245, 0), } data, _ := json.Marshal(user) fmt.Println(string(data)) // {\u0026#34;userId\u0026#34;:20060102150405,\u0026#34;password\u0026#34;:\u0026#34;zwei\u0026#34;,\u0026#34;birthday\u0026#34;:\u0026#34;2006-01-02T15:04:05Z\u0026#34;} } 通过 tag 为结构体字段编写元信息，这是 go 语言的语法，并在运行时通过反射解析。\njson tag 的编写规则 标准库 encoding/json 规定了 json tag 的编写规则：\n如果值为 - ，意味着跳过该字段的解析：json:\u0026quot;-\u0026quot;。 公有的结构体字段才会被解析。未导出的字段，即便有 json tag，也无法生效。 tag 的语法为：json:\u0026quot;${name},${opt1},${opt2}\u0026quot;。 其中 ${name} 用于指定 JSON 的键名，如果为空，取结构体字段名。此外，标准库还提供了可选项，用于开发者控制 JSON 编解码的结果。\n以 , 分割选项，可以没有选项，也可以有多个选项。目前的选项可选值为 string, omitempty, omitzero 这 3 个。 选项 string，表示该字段生成的 json键值的类型是字符串，这个选项只对 整型、浮点型、布尔型、字符型有效。 选项 omitempty 表示如果该字段为空值，生成的 JSON 键值对将会被忽略。 选项 omitzero 表示如果该字段为零值，生成的 JSON 键值对将会被忽略。 上述的规则，都能够从标准库的源码 /src/encoding/json/encode.go 中找到对应的解析过程：\nsf := f.typ.Field(i) ... // 跳过结构体未导出的字段 if !sf.IsExported() { continue } ... tag := sf.Tag.Get(\u0026#34;json\u0026#34;) if tag == \u0026#34;-\u0026#34; { continue } // 解析 json tag 的值，获取字段名和拓展选项 name, opts := parseTag(tag) ... // 只有 strings, floats, integers, and booleans 才可以被 \u0026#34;\u0026#34; 包裹. quoted := false if opts.Contains(\u0026#34;string\u0026#34;) { switch ft.Kind() { case reflect.Bool, reflect.Int, reflect.String, ...: quoted = true } } ... // 如果 json tag 的值为空, 取结构体字段名 if name == \u0026#34;\u0026#34; { name = sf.Name } field := field{ name: name, omitEmpty: opts.Contains(\u0026#34;omitempty\u0026#34;), omitZero: opts.Contains(\u0026#34;omitzero\u0026#34;), quoted: quoted, } omitempty 选项是 go1.1 版本就提供的功能，用于跳过空值的字段。但由于预定义的空值判断，无法满足所有实际场景的需求，因此在 go1.24 的时候，引入 omitzero 选项。具体的可查阅：JSON包新提案：用“omitzero”解决编码中的空值困局 | Tony Bai\n希望 JSON 标准库能够提供一个接口，用于指定 json tag 为空时的键名规则，而不是默认使用结构体字段值，这样可以少写很多 json tag。\n自定义 JSON 的编解码实现 JSON 标准库提供了 Marshaler 和 Unmarshaler 这两个接口定义：\ntype Marshaler interface { MarshalJSON() ([]byte, error) } type Unmarshaler interface { UnmarshalJSON([]byte) error } 如果在序列化和反序列化的过程中，JSON 标准库检测到类型实现了上述接口，那么就会使用接口的方法进行编解码，这也为 JSON 的编解码提供更多的功能，下面笔者将会介绍相关的应用技巧。\n使用的例子都以 User 结构体为原型：\ntype User struct { UserId int64 `json:\u0026#34;userId\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` Birthday time.Time `json:\u0026#34;birthday\u0026#34;` } 动态添加字段 如果我们希望得到的 JSON 对象还包含 \u0026quot;age\u0026quot;: ${age} 这个键值对，age 表示当前用户的年龄，应该根据当前时间 time.Now 减去 User.Birthday 得到。很明显，为 User 结构体增加 Age 字段会增加维护成本，这时候为 User 结构体实现标准库定义的 json.Marshaler 接口，就可以一劳永逸：\nfunc (u User) MarshalJSON() ([]byte, error) { type Format struct { UserId int64 `json:\u0026#34;userId\u0026#34;` Password string `json:\u0026#34;password\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } age := time.Now().Year() - u.Birthday.Year() if time.Now().YearDay() \u0026lt; u.Birthday.YearDay() { age-- } return json.Marshal(Format{ UserId: u.UserId, Password: u.Password, Age: age, }) } func main() { user := User{ UserId: 20060102150405, Password: \u0026#34;zwei\u0026#34;, Birthday: time.Unix(1136214245, 0), } data, _ := json.Marshal(user) fmt.Println(string(data)) // {\u0026#34;userId\u0026#34;:20060102150405,\u0026#34;password\u0026#34;:\u0026#34;zwei\u0026#34;,\u0026#34;age\u0026#34;:19} } 如果字段比较多，全部重写就比较麻烦了，这时候可以通过「类型定义」和「结构体内嵌」的方式来简化：\nfunc (u User) MarshalJSON() ([]byte, error) { type NewUser User type Format struct { NewUser Age int `json:\u0026#34;age\u0026#34;` } age := time.Now().Year() - u.Birthday.Year() if time.Now().YearDay() \u0026lt; u.Birthday.YearDay() { age-- } return json.Marshal(Format{ NewUser: NewUser(u), Age: age, }) } 这里之所以使用类型定义：type NewUser User，是因为 Format 直接内嵌 User 结构体的话，就会继承其 MarshalJSON 的方法，那么就会陷入无限循环中，最后导致栈溢出。而使用类型定义，只会复用原始结构体字段，而不会继承其方法。\ngo 官方文档里就很明确的提到了这一点：Type_definitions\n修改字段序列化格式 User.Birthday 的类型为 time.Time，JSON 标准库只会序列化为 RFC3339 格式（time.RFC3339 = \u0026quot;2006-01-02T15:04:05Z07:00\u0026quot;），如果需要序列化为时间戳或其他格式，在实现 json.Marshaler 接口时，效仿 修改键值类型 的操作，即可实现：\nfunc (u *User) MarshalJSON() ([]byte, error) { type NewUser User type Format struct { *NewUser Birthday int64 `json:\u0026#34;birthday\u0026#34;` } return json.Marshal(Format{ NewUser: (*NewUser)(u), Birthday: u.Birthday.Unix(), }) } 重新运行程序：\nfunc main() { user := User{ UserId: 20060102150405, Password: \u0026#34;zwei\u0026#34;, Birthday: time.Unix(1136214245, 0), } data, _ := json.Marshal(\u0026amp;user) fmt.Println(string(data)) // {\u0026#34;userId\u0026#34;:20060102150405,\u0026#34;password\u0026#34;:\u0026#34;zwei\u0026#34;,\u0026#34;birthday\u0026#34;:1136214245} } 可以看到 Format.Birthday 成功覆盖了 Format.NewUser.Birthday，这是因为外层的字段优先级更高。具体缘由，读者可以在标准库的源码中查看：encoding/json/encode.go\n当前部分的接口实现和 修改键值类型 的略有不同，笔者将值接收者 func (u User) 改成了指针接收者 func (u *User)，这也导致了 json.Marshal(user) 需要写成 json.Marshal(\u0026amp;user)。\n用于体现了「值接收」和「指针接收」的区别，具体的可查看 go 团队的 FAQ ：Why do T and *T have different method sets?\n敏感字段处理 在前面的例子中，实现了字段的新增和修改，这一部分则是介绍如何隐藏 JSON 的键值对。像密码 Password 作为敏感数据，是不应该返回到前端的，但仍然需要反序列化，因此不能使用 json:\u0026quot;-\u0026quot;，因为这个 tag 会直接跳过 Password 的反序列化。那么就可以在实现接口时，将 Password 的值置空：\nfunc (u User) MarshalJSON() ([]byte, error) { type NewUser User newUser := NewUser(u) newUser.Password = \u0026#34;\u0026#34; return json.Marshal(newUser) } 但也有不足之处，如果有多个结构体都含有 Password 字段，那么修改起来就变得非常繁琐了。\n那么在介绍解决办法之前，还请读者做个题，下面代码的运行结果为：\nfunc main() { var password *string err1 := json.Unmarshal([]byte(`\u0026#34;zwei\u0026#34;`), \u0026amp;password) if err1 != nil { panic(err1) } output, err2 := json.Marshal(*password) if err2 != nil { panic(err2) } fmt.Println(string(output)) // 上面代码在尝试对字符串进行 json.Unmarshal 和 json.Marshal // 看有几种可能： // A. err1 != nil \u0026amp;\u0026amp; panic(err1) // B. *password -\u0026gt; panic: nil pointer // C. err2 != nil \u0026amp;\u0026amp; panic(err2) // D. fmt.Println(string(output)) } 假设程序能够正常运行，这对置空 Password 的实现会有什么帮助呢？\n一个简单的想法，如果能为 Password 实现 json.Marshaler 接口，将序列化的值设置为空字符串，就不用担心 Password 的泄露了。\n而事实上，上述代码是能够正常运行的，因为字符串本就是 JSON 的数据类型，所以字符串也是可以被序列化和反序列化的。上面的代码在执行：json.Unmarshal 后，password 的值就是 zwei 了。再执行 json.Marshal，就会序列化为 \u0026quot;zwei\u0026quot;，这也就是 output 的值。\n为了帮助 Password 实现 json.Marshaler 接口，需要先定义 type Password string，因为 string 作为内置类型，不支持为其编写方法。\n具体实现也极其简单：\ntype Password string func (p Password) MarshalJSON() ([]byte, error) { return []byte(`\u0026#34;\u0026#34;`), nil } 通过这样实现 Password 的隐藏，也更贴近设计模式中的单一职责。为 Password 拓展功能也会变得更加简单，比如实现标准库的 sql.Scanner (database/sql.go) 接口 和 driver.Valuer (database/sql/types.go) 接口，实现自动加密和解密。\n笔者以 driver.Valuer 为例：\nimport \u0026#34;golang.org/x/crypto/bcrypt\u0026#34; func (p Password) Value() (driver.Value, error) { if len(p) == 0 { return nil, nil } hash, err := bcrypt.GenerateFromPassword([]byte(p), bcrypt.DefaultCost) if err != nil { return nil, err } return string(hash), nil } 当 Password 不为空时，就能转化为数据库所需要的加密字符串。\n","date":"2025-03-09T13:23:15+08:00","permalink":"https://niluan304.github.io/p/json-%E6%A0%87%E5%87%86%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/","title":"JSON 标准库的使用技巧"},{"content":"起因：远程开关机的需求 笔者6月初组了台式，并将主机置于角落，按下物理的开关键变得很麻烦，因此有了远程开关机的需求。 经过了解后，发现远程开关机有三种方式：\n主板通电开机 + 智能插座物理断电关机 安装 PCIe 开机卡 Wake On Lan + SSH关机 智能插座 开机 现代主板都有来电自启动这个功能，开启之后，搭配智能插座的远程通断电功能，如米家插座，就可以远程开机了。\n智能插座一般都依赖于路由器提供Wi-Fi，以接入物联网 Internet of Things(IoT) 软件 关机 通过智能插座的物理断电以强制关机。\n优缺点\n实现简单：只需要购买智能插座和开启主板的来电自启 花费：¥40 智能插座 开机慢： 主板在通电后首次开机，自检项目很多，导致开机时间被延长 断电关机有风险：如果在传输数据过程中关机，操作系统可能会来不及保存数据而造成文件损坏 向日葵智能插座提供了软关机的方式，但需要后台运行向日葵监控软件 PCIe 开机卡 按下机箱上的开机键，会让电脑开关机，其本质就是短接下主板的 power on/off 针脚，而接入 PCIe 开机卡则是能够通过 IoT 软件中发出开关机的指令。\n接入 PCIe 开机卡，同样需要路由器提供Wi-Fi，才能接入 IoT 软件。\n优缺点\n规避了物理通断电的缺点 会占用主板上的 PCIe 槽，虽然不会抢带宽 花费：¥40 PCIe 开机卡 部分厂商无法接入米家 Wake On Lan + SSH关机 开机：网络唤醒 Wake on LAN (WoL)，设备通过局域网向目标主机的网卡发送指令，网卡就会通知所在主板开机。 关机：设备通过SSH远程登录指定主机，然后执行关机指令。\n优缺点：\n需要额外的且24h 运行的设备 如果能够解锁路由器的SSH，就可以用路由器充当这个设备。否则需要考虑 NAS，软路由等。 实现麻烦： 开启 WoL，需要调整主板，系统内的设置，SSH 远程指令，更是大坑 花费：¥0，现有设备，才应该考虑这个方案。 出于折腾和省钱的目的，笔者选择了第三种方案。\n警告 刷机，乃至于开启 SSH都有可能失去官方保修，请谨慎操作 小米路由器开启SSH 对系统版本有要求，新版本固件很可能不支持开启SSH 前期准备 注册巴法云账号 注册一个巴法云账户，并添加一个006后缀的主题。\n可参考：平台操作教程 | 巴法文档中心\n步骤如下：\n打开 巴法物联网云平台，使用邮箱或手机注册。 点击「控制台」，拷贝自己的私钥，后续会用到。 新建主题-命名为 pc006，名称可以为任意英文，但必须以006结尾，表示开关设备。 效果如图： 点击「昵称」，网页会弹出「修改昵称」的窗口，以供自定义。 为受控电脑安装 SSH 服务 Windows 具体的安装方法请参考：Windows 上的 OpenSSH：安装、配置和使用指南 - 系统极客\n在开始安装 OpenSSH 之前，请确保你的电脑满足以下条件：\n操作系统：Windows 11 或 Windows 10（1809 版本或更高）。 PowerShell 版本：PowerShell 5.1 或以上。 管理员权限：安装 OpenSSH 需要拥有管理员权限。 Linux Linux 电脑一般都安装 OpenSSH，如果没有可以通过各发行版的包管理工具安装：\nDebian 、Ubuntu\nsudo apt install ssh CentOs\nsudo yum install openssh-server 开启受控电脑的 Wake On Lan 开启主板的 WoL 想要使用网络唤醒（Wake-on-LAN，WoL），也需要开启主板BIOS的 WoL 功能，各厂商的主板开启方式不一致，具体方法视厂商而定，进入 BIOS 后注意选项附加的说明即可，可以参考的关键词包括：\nAutomatic Power On Wake on LAN/WLAN Power Management Power On by Onboard LAN Power On by PCI-E Devices 关闭主板的电源节能设置 很多厂商的主板都有低功耗模式，为了节能，该模式下，电脑关机后，会彻底关闭网卡，会无法使用 WoL ，因此需要关闭此类模式。可以参考的关键词包括：\nErP EUP windows 系统设置 配置网卡 在 Windows 10 中，运行 \u0026gt; ncpa.cpl 打开「网络连接」设置，然后找到当前在使用的有线网卡，右键点击「属性」：\n点击「配置」：\n切换到「电源管理」，勾选「允许此设备唤醒计算机」以及「只允许幻数据包唤醒计算机」：\n关闭快速启动 先点击「更改当前不可用的设置」，以便能修改关机设置 关闭「启用快速启动」（快速启动（Fast Startup），属于 S4 电源状态，不支持网络唤醒） 部署 pc 笔者编写了一个小应用（下文称为 pc），依赖于 WakeOnLan、巴法云和SSH协议，实现了远程开关机：\nsequenceDiagram actor user AS 用户 participant iot AS iot(小爱同学) participant bemfa AS 巴法云 participant power AS pc participant pc AS 电脑 rect rgb(191, 223, 255) Note over user,pc: 远程关机 user -\u0026gt;\u0026gt;+ iot: 语音：关电脑 iot -\u0026gt;\u0026gt; bemfa: 推送消息：\u0026#34;off\u0026#34; bemfa -\u0026gt;\u0026gt; power: TCP(\u0026#34;off\u0026#34;) power -\u0026gt;\u0026gt; pc: SSH(\u0026#34;关机\u0026#34;) pc -\u0026gt;\u0026gt; pc: 关机 iot --)- user: ok（异步） end rect rgb(248,240,233) Note over user,pc: 远程开机 user -\u0026gt;\u0026gt;+ iot: 语音：开电脑 iot -\u0026gt;\u0026gt; bemfa: 推送消息：\u0026#34;on\u0026#34; bemfa -\u0026gt;\u0026gt; power: TCP(\u0026#34;on\u0026#34;) power -\u0026gt;\u0026gt; pc: WoL \u0026amp; SSH(\u0026#34;取消关机\u0026#34;) pc -\u0026gt;\u0026gt; pc: 开机 iot --)- user: ok（异步） end 开启设备的 SSH/Telnet pc 需要运行在局域网内不停机的机器上，如路由器、NAS。\n因此需要能登录到目标机器上，然后下载并运行pc。最常用的远程登录协议为 SSH，搭配 SCP 操作文件系统也会更方便。\n某些设备只能启用 Telnet 协议，无法启用 SSH ，操作会繁琐一些。 以笔者的小米路由器 AX3000T（1.0.47版本下）为例，开启SSH的步骤：\n登录路由器后台，复制 stok变量\n将脚本内容保存到 stok.bat 文件中，执行后并输入复制的stok变量，\n@REM 使用 UTF8 编码，以正确显示中文 chcp 65001 @echo off @REM \u0026lt;STOK\u0026gt;修改为复制的变量 echo Input the ^\u0026lt;STOK^\u0026gt; in admin page of your Xiaomi router echo 输入你小米路由器中后台页面中的 ^\u0026lt;STOK^\u0026gt; set /p STOK= @REM echo %STOK% curl -X POST http://192.168.31.1/cgi-bin/luci/;stok=%STOK%/api/misystem/arn_switch -d \u0026#34;open=1\u0026amp;model=1\u0026amp;level=%0Anvram%20set%20ssh_en%3D1%0A\u0026#34; curl -X POST http://192.168.31.1/cgi-bin/luci/;stok=%STOK%/api/misystem/arn_switch -d \u0026#34;open=1\u0026amp;model=1\u0026amp;level=%0Anvram%20commit%0A\u0026#34; curl -X POST http://192.168.31.1/cgi-bin/luci/;stok=%STOK%/api/misystem/arn_switch -d \u0026#34;open=1\u0026amp;model=1\u0026amp;level=%0Ased%20-i%20\u0026#39;s%2Fchannel%3D.*%2Fchannel%3D%22debug%22%2Fg\u0026#39;%20%2Fetc%2Finit.d%2Fdropbear%0A\u0026#34; curl -X POST http://192.168.31.1/cgi-bin/luci/;stok=%STOK%/api/misystem/arn_switch -d \u0026#34;open=1\u0026amp;model=1\u0026amp;level=%0A%2Fetc%2Finit.d%2Fdropbear%20start%0A\u0026#34; pause 效果大概是这样的：\n也可以逐行复制到 cmd 执行，可参考：小米AX3000T解锁SSH ＆固化SSH 下载 pc 根据设备的芯片架构及安装的操作系统，找到对应的压缩包：Release\n如果是 Linux/OpenWrt 系统，可以在命令行输入 cat /etc/os-release | grep ARCH 以查看设备的架构，以笔者的为例：\ncat /etc/os-release | grep ARCH LEDE_ARCH=\u0026#34;aarch64_cortex-a53\u0026#34; # cortex-a53 是 实现ARMv8-A 64位指令集的微架构，故 CPU 是 arm64架构的 在目标设备中，将解压后的二进制文件及配置文件移动到可读写的文件夹，实现方式有两种：\n直接通过 curl 或 wget 命令下载压缩包后解压 在其他设备上下载后，通过 scp 等协议上传到设备 修改配置文件 pc 使用 yaml文件作为配置文件，使用前，使用者应当熟悉一下 yaml 的基本语法，以修改或补全空白配置项的值：\n# 当前程序所在主机的局域网IP，即通过 SSH/Telnet 登录的设备，一般为路由器/NAS # 小米路由器的局域网IP一般为：192.168.31.1 myIP: \u0026#34;\u0026#34; # 目标主机的主板网卡MAC地址， # windows 机器可以在命令行中输入 `ipconfig /all` 查看，如：00-1B-44-11-3A-B7 targetMac: \u0026#34;\u0026#34; # ssh 配置 ssh: # 目标主机的 IP + SSH 端口号 # host:port 如 192.168.31.111:11022 addr: \u0026#34;\u0026#34; # 用户名，目前支持私钥和密码登录 user: \u0026#34;\u0026#34; # 私钥路径，建议使用绝对地 # 通过公私钥登录，推荐使用 # # 私钥可通过其他设备上的 `ssh-keygen -t ed25519 -f ed25519` 命令生成 # 然后将 ed25519 私钥上传至运行设备上 identity: \u0026#34;\u0026#34; # 使用密码登录，可选项 # 密码明文，应当在局域网环境使用 password: \u0026#34;\u0026#34; # 日志设置 log: # 日志文件位置，默认为 pc.log file: /tmp/log/pc.log # 是否打印代码位置 addSource: false # 日志级别 # 定义见 log/slog/level.go:43 # LevelDebug Level = -4 # LevelInfo Level = 0 # LevelWarn Level = 4 # LevelError Level = 8 level: 0 bemfa: # 巴法云的 UID，即控制台的私钥 uid: \u0026#34;\u0026#34; # topic-switch switch: # 主题的名称 topic: XXX006 # Switch 只接收 on/off 两种指令，对应的操作 # 覆盖这里的指令之前，你应该在默认的 shell，Linux(sh)/Windows(cmd) 中测试一下，以确保关机指令和取消指令是正确的。 on: cmd /c shutdown /a off: cmd /c shutdown /s /t 600 调试 pc 运行 pc\n# Linux 机器上，赋予 `pc` 执行权限 chmod +x pc # 指定配置文件并运行 ./pc -config config.yml 通过巴法云推送消息\n在巴法云控制台，如果连接正常，pc 订阅的主题上，会显示订阅者的在线数量： 设备（Windows）处于开机状态\n推送 off，弹窗显示，即将关机：\n推送 on，弹窗显示，关机被取消：\n设备处于关机机状态\n推送 off，设备无反应 推送 on，设备 开机 后台运行 pc 若调试后无问题，即可在设备上后台运行 pc, 以捕获巴法云的消息推送\n./pc -config config.yml \u0026amp; 巴法云接入 iot 软件\n米家： ","date":"2024-06-16T23:53:49+08:00","permalink":"https://niluan304.github.io/p/%E6%8A%98%E8%85%BE%E7%AC%94%E8%AE%B0%E5%9C%A8%E5%B0%8F%E7%B1%B3%E8%B7%AF%E7%94%B1%E5%99%A8%E5%8E%9F%E7%94%9F%E7%B3%BB%E7%BB%9F%E4%B8%8A%E9%83%A8%E7%BD%B2%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%94%E7%94%A8%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%85%B3%E6%9C%BA/","title":"折腾笔记：在小米路由器原生系统上部署自定义应用，实现远程开关机"},{"content":"这段时间面试，遇到了一道和实际生产相关的面试题：\n现有一系统，积分使用 MongoDB 存储，点券存储在 MySQL。\n用户通过日常任务获取积分，点券则可以提现。\n现推出一活动 1000 积分兑换 10 点券，怎么实现？\n和缓存一致性的不同 对于这种跨数据库之间的操作，可能会误认为类似「如何实现 MySQL 和 Redis 的数据一致性？」，但两者之间其实很不同，Redis 在这种场景一般用于充当远程缓存或分布式缓存数据库，其本质上是将数据从支持持久化但慢速的磁盘中，搬到断电丢失但高速的内存中。也就是说，在实现 MySQL、Redis 数据一致性时，我们操作的仍是同一份数据，考虑得比较多的是避免用户读取到脏数据（旧数据）。\n而题目的要求其实是：如何解决分布式数据库在双写时的数据一致性？\n分布式事务 面试的时候，笔者联想到了跨行转账，跨行转账业务有三种情况：\n相同支行下的转账：同一支行内的转账（本地事务） 不同支行下的转账：相同银行，不同支行下的转账 （分布式事务） 跨行转账：和其他银行系统进行转账 （分布式事务） 假设银行以支行为最小单位，进行数据库部署\n而这道题很像场景二，比如「用户A 是工行深圳支行的用户，用户B 是工行广州支行的用户，A向B转账100元」，虽然都是 A 和 B 都是工行用户，但是 A 和 B 的数据并不在同一个数据库，那么就需要两个数据库之间的进行数据交换，这时候无法通过本地数据库的事务实现 ACID，一般通过分布式事务解决的。\n查询确认事务结果 场景二下，可以认为在工行这个大系统，内部有由深圳支行和广州支行的这样微服务组成，而微服务之间的业务流转相对简单一些：\n深圳支行扣除用户A 的100元。 深圳支行通知广州支行，用户A要转账 100元 给用户B。 深圳支行定时向广州支行查询是否收到了转账，如果失败了那就回滚。 具体流程大概是这样：\n深圳支行的用户A 发起转账请求，开启事务 深圳支行创建转账订单，记录用户A 的支出和转账前后点券，且状态设置为「支出中」 深圳支行通知广州支行，用户A 向 用户B 转账，广州支行收到通知后： 开启事务 创建转账订单，记录用户B 的收入和转账前后点券，且状态设置为「收入中」 更新订单状态，并返回转账结果给深圳支行 深圳支行收到广州支行的回复： 成功：转账订单状态更新为「成功」，提交事务 失败：转账订单状态更新为「失败」，回滚事务 %% 时序图 [Markdown 进阶技能：用代码画时序图](https://zhuanlan.zhihu.com/p/70261692) %% -\u0026gt;\u0026gt;实线箭头 代表主动发出消息；--\u0026gt;虚线代表响应；末尾带「X」代表异步消息，无需等待回应。 sequenceDiagram participant 用户A participant 深圳支行 participant 广州支行 participant 用户B 用户A -\u0026gt;\u0026gt; + 深圳支行: 向用户B 转账 深圳支行 -\u0026gt;\u0026gt; 深圳支行: 创建转账订单，状态 PAYOUT 深圳支行 -\u0026gt;\u0026gt; 深圳支行: 事务 BEGIN 深圳支行 -\u0026gt;\u0026gt; + 广州支行: A向B转账 广州支行 -\u0026gt;\u0026gt; 用户B: 执行转账操作 用户B --\u0026gt;\u0026gt; 广州支行: 转账结果 alt 转账成功 用户B --\u0026gt;\u0026gt; 广州支行: 订单状态 SUCC else 转账失败 用户B --\u0026gt;\u0026gt; 广州支行: 订单状态 FAIL end 广州支行 --\u0026gt;\u0026gt; - 深圳支行: 转账结果 alt 转账成功 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 订单状态 SUCC 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 事务 COMMIT else 转账失败 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 订单状态 FAIL 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 事务 ROLLBAK end 深圳支行 --\u0026gt;\u0026gt; - 用户A: 收到转账结果 在上述流程是同步的，用户需要在转账界面等待转账结果，如果转账耗时过久，会影响到用户体验。可以将转账结果改成异步事件。\n在用户提交转账请求后，返回提示：「转账请求已提交，请稍后查看转账结果」，用户就可以先浏览其他页面，等待转账结果的推送。\n%% 时序图 [Markdown 进阶技能：用代码画时序图](https://zhuanlan.zhihu.com/p/70261692) %% -\u0026gt;\u0026gt;实线箭头 代表主动发出消息；--\u0026gt;虚线代表响应；末尾带「X」代表异步消息，无需等待回应。 sequenceDiagram participant 用户A participant 深圳支行 participant 广州支行 participant 用户B 用户A -\u0026gt;\u0026gt; + 深圳支行: 向用户B转账 深圳支行 -\u0026gt;\u0026gt; 深圳支行: 创建转账订单，状态 PAYOUT 深圳支行 --\u0026gt;\u0026gt; - 用户A: 稍后查看转账结果 深圳支行 -\u0026gt;\u0026gt; + 深圳支行: 事务 BEGIN 深圳支行 -\u0026gt;\u0026gt; 广州支行: A向B转账 广州支行 -\u0026gt;\u0026gt; 用户B: 执行转账操作 用户B --\u0026gt;\u0026gt; 广州支行: 转账结果 loop 定时查询 深圳支行 -\u0026gt;\u0026gt; 广州支行: 转账订单状态 广州支行 --\u0026gt;\u0026gt; 深圳支行: 转账订单结果 end alt 转账成功 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 订单状态 SUCC 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 事务 COMMIT else 转账失败 深圳支行 --\u0026gt;\u0026gt; 深圳支行: 订单状态 FAIL 深圳支行 --\u0026gt;\u0026gt; - 深圳支行: 事务 ROLLBACK end 深圳支行 -\u0026gt;\u0026gt; 用户A: 转账结果 二阶段提交协议 2PC 与 MySQL单机中的 2PL 有相似点，都有两个阶段，但适用的目标是不一样的，不能混淆。\n二阶段加锁协议（Two-Phase Locking, 2PL）：一种用于管理数据库事务并发控制的协议，主要目的是防止多个事务同时修改同一数据项，以避免数据不一致的问题，实现可序列化的隔离等级。 二阶段提交协议（Two-Phase Commit, 2PC） ：一种用于实现分布式系统中的原子性操作的协议，确保所有的事务参与者要么全部提交，要么全部回滚，从而保证分布式事务的完整性。 2PC 的基本流程如下： 2PC的相关内容，见设计密集型应用（Designing Data-Intensive Applications, DDIA）「第九章：一致性与共识」，笔者就不赘述了。\n依赖关系：MySQL 为主 面试官表示分布式事务是更通用的解决方法，如果用到 MySQL 和 MongoDB 都是本地数据库这个条件，这题可以有更好的处理方法。面试结束后，伟大的互联网告诉笔者确实如此。\nMySQL 存储点券，MongoDB 存储积分，很明显点券是核心数据，那么需要以 MySQL 为主，所以MySQL 中应该有一个字段 mongo_id 用于关联 MongoDB 的主键 _id，而查询 MongoDB 存储的积分，只能通过 MySQL 里 mongo_id 字段。\n假设 MySQL 表结构如下：\nCREATE TABLE wallet ( user_id INT PRIMARY KEY COMMENT \u0026#39;userId\u0026#39;, balance DECIMAL(10, 0) DEFAULT NULL COMMENT \u0026#39;点券\u0026#39;, mongo_id VARCHAR(64) NOT NULL COMMENT \u0026#39;MongoDB 主键id\u0026#39; ); MongoDB 文档结构如下：\n{ \u0026#34;_id\u0026#34;: \u0026#34;661bcb98cd3500008c007b5c\u0026#34;, \u0026#34;score\u0026#34;: 200 } 主要思想是借鉴预写日志（Write Ahead Log, WAL），实现 MySQL 与 MongoDB 的双写一致性：\n开启 MySQL 事务，避免并发问题 先在 MongoDB 插入修改后的数据，而不是去更新 MongoDB 再更新 MySQL 的 mongo_id。 具体流程如下：\n%% 时序图 [Markdown 进阶技能：用代码画时序图](https://zhuanlan.zhihu.com/p/70261692) %% -\u0026gt;\u0026gt;实线箭头 代表主动发出消息；--\u0026gt;虚线代表响应；末尾带「X」代表异步消息，无需等待回应。 sequenceDiagram participant 用户 participant 系统 participant MySQL participant MongoDB 用户 -\u0026gt;\u0026gt; + 系统: 积分兑换点券 系统 -\u0026gt;\u0026gt; MySQL: 事务 BEGIN 系统 -\u0026gt;\u0026gt; MySQL: 查询 user_id MySQL --\u0026gt;\u0026gt; 系统: 返回 blance, mongo_id 系统 -\u0026gt;\u0026gt; MongoDB: 查询 mongo_id MongoDB --\u0026gt;\u0026gt; 系统: 返回 document 系统 -\u0026gt;\u0026gt; 系统: document.score -= 100 系统 -\u0026gt;\u0026gt; MongoDB: 插入修改后的 document MongoDB --\u0026gt;\u0026gt; 系统: 返回 mongo_id 系统 -\u0026gt;\u0026gt; MySQL: 更新 blance, mongo_id MySQL --\u0026gt;\u0026gt; 系统: 更新成功 MySQL --\u0026gt;\u0026gt; 系统: 事务 COMMIT 系统 --\u0026gt;\u0026gt; - 用户: 兑换完成 在这个流程中，无论什么时候写入出错，都不会影响到数据的一致性。\n如果在 MongoDB 插入新数据时出错，MySQL 中保存的仍为老数据。 如果在 MySQL 更新时出错，MySQL 中保存的仍为老数据。 不过这种方案会带来一个问题，MongoDB 会新增一条无效的垃圾数据，解决方法有两种：\n异步删除。通过带有重试机制的消息队列，直到垃圾数据被删除。 定时器删除。通过定时器，查询出近段时间垃圾数据，并做删除。 参考资料 分布式事务：如何保证多个系统间的数据是一致的？ 如何保证mongodb和数据库双写数据一致性？ 分布式事务概述 一致性问题与分布式事务 以银行转账为例分析分布式事务的解决方案 ","date":"2024-04-15T09:52:02+08:00","permalink":"https://niluan304.github.io/p/%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%9C%AC%E5%9C%B0-mysql-%E5%92%8C-mongodb-%E5%8F%8C%E5%86%99%E6%97%B6%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7/","title":"如何实现本地 MySQL 和 MongoDB 双写时数据一致性"},{"content":" 源代码/数据集已上传到：GitHub - follow gee to learn go\nGoFrame 的 ReqResFunc 类型 在 day7.5 开篇的时候，笔者提到 GoFrame 支持第二种路由注册方法，这里笔者称之为 ReqResFunc 类型（下文同）：\n// 写法二 func (ctx context.Context, req *{Prefix}Req) (res *{Prefix}Res, err error){ // 业务代码逻辑 } 但是 day9 实现的函数签名：\nfunc (c *user) Get(ctx context.Context, decode func(point any) (err error)) (data any, err error) 对比可以发现，和 ReqResFunc 类型有明显不同，我们可以在 GoFrame 的源码里一探究竟。\n从 GoFrame 的 文档「路由注册-函数注册」中，可以找到 入口函数：\n// https://github.com/gogf/gf/blob/313d9d138f96b0ed460d47684298a7fb26d3fd75/net/ghttp/ghttp_server_service_handler.go#L21-L39 // BindHandler registers a handler function to server with a given pattern. // // Note that the parameter `handler` can be type of: // 1. func(*ghttp.Request) // 2. func(context.Context, BizRequest)(BizResponse, error) func (s *Server) BindHandler(pattern string, handler interface{}) { var ctx = context.TODO() funcInfo, err := s.checkAndCreateFuncInfo(handler, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;) if err != nil { s.Logger().Fatalf(ctx, `%+v`, err) } s.doBindHandler(ctx, doBindHandlerInput{ Prefix: \u0026#34;\u0026#34;, Pattern: pattern, FuncInfo: funcInfo, Middleware: nil, Source: \u0026#34;\u0026#34;, }) } 在源码里，可以发现关键代码在 checkAndCreateFuncInfo 方法，继续前行，就能够发现端倪：\n// https://github.com/gogf/gf/blob/313d9d138f96b0ed460d47684298a7fb26d3fd75/net/ghttp/ghttp_server_service_handler.go#L148 func (s *Server) checkAndCreateFuncInfo(f interface{}, pkgPath, structName,methodName string,) (funcInfo handlerFuncInfo, err error) { funcInfo = handlerFuncInfo{ // 根据传入的 f，初始化返回值 Type: reflect.TypeOf(f), Value: reflect.ValueOf(f), } } GoFrame 通过反射 reflect，获取了传入的函数的参数信息，并做了相应的校验，关键代码有 5 行：\n// 校验请求和返回的参数数量 if reflectType.NumIn() != 2 || reflectType.NumOut() != 2 // 第一个请求参数必须为 context.Context 类型 if !reflectType.In(0).Implements(reflect.TypeOf((*context.Context)(nil)).Elem()) // 第二个返回参数必须为 error 类型 if !reflectType.Out(1).Implements(reflect.TypeOf((*error)(nil)).Elem()) // 第二个请求参数必须为以 `Req` 结尾 if !strings.HasSuffix(reflectType.In(1).String(), `Req`) // 第一个返回参数必须为以 `Res` 结尾 if !strings.HasSuffix(reflectType.Out(0).String(), `Res`) 通过这些校验，GoFrame 就实现了规范路由函数必须是 ResReqFunc 类型的约束。校验过程中，有一些细节：\nctx 和 error 是接口类型，只能调用 func (Type) Implements(u Type) bool 确认是否实现了对应的接口，(*error)(nil) 和 (*context.Context)(nil) 则是声明了对应接口的空值 nil。 req 和 res 的初始类型是结构体，可以直接获取结构体的类型名。 实现 ReqResFunc 类型的约束 接下来，我们就可以仿照 GoFrame，实现 ResReqFunc 类型的约束。首先需要创建一个结构体，用于保存反射解析出来的值：\ntype ReqResFunc struct { fn reflect.Value // 函数调用入口 ctx reflect.Type // 第一个请求参数：context.Context req reflect.Type // 第二个请求参数：XXXReq res reflect.Type // 第一个返回参数：XXXRes err reflect.Type // 第二个返回参数：error } 具体的解析代码，可以全部仿照 GoFrame 的流程，获取入参 reqRes 的反射对象，然后逐个校验，最后再构造 ReqResFunc。\n那么还剩最后一个问题， ReqResFunc 要注册到 Gin框架里呢？这里和 day9 遇到的情况一样，还是那句名言：\nAll problems in computer science can be solved by another level of indirection.\n计算机科学领域的任何问题都可以通过增加一个中间层来解决。\n倘若解决不了，那就再加一个中间层，因此完全可以把 ReqResFunc 转换为 DecodeFunc，实现也不复杂：\nfunc (f *ReqResFunc) Call(ctx context.Context, decode func(point any) error) (any, error) { req := reflect.New(f.req.Elem()) point := req.Interface() if err := decode(point); err != nil { return nil, err } result := f.fn.Call([]reflect.Value{reflect.ValueOf(ctx), req}) if err := result[1]; !err.IsNil() { return nil, err.Interface().(error) } return result[0].Interface(), nil } func (f *ReqResFunc) DecodeFunc() DecodeFunc { return f.Call } 而 GoFrame 也是这样转化的，相关源码： func createRouterFunc(funcInfo handlerFuncInfo) func(r *Request)\n验证 ReqResFunc 类型 增加了一个新特性，做个简单测试，通过 teamId 获取团队成员：\n// internal/controller/controller.go func (c *team) GetUsers(ctx context.Context, req *TeamGetUsersReq) (res *TeamGetUsersRes, err error) { out, err := service.Team.GetUsers(ctx, \u0026amp;service.TeamGetUsersReq{Id: req.Id}) if err != nil { return nil, err } return \u0026amp;TeamGetUsersRes{TeamGetUsersRes: out}, nil } // internal/service/service.go func (s *team) GetUsers(ctx context.Context, req *TeamGetUsersReq) (res *TeamGetUsersRes, err error) { var users []UserGetRes // 查询数据 // Users 只是一个切片 []User，用于充当数据库 for _, row := range db.Users { if row.TeamId == req.Id { users = append(users, UserGetRes{Id: row.Id, Name: row.Name, TeamId: row.TeamId}) } } return \u0026amp;TeamGetUsersRes{Users: users}, nil } 测试接口：\nfunc Test_Client(t *testing.T) { time.Sleep(time.Second) // 等待服务端启动 paths := []string{ \u0026#34;/user/1\u0026#34;, // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;teamId\u0026#34;:1}} \u0026#34;/user/3\u0026#34;, // {\u0026#34;code\u0026#34;:400,\u0026#34;msg\u0026#34;:\u0026#34;user not found: 3\u0026#34;,\u0026#34;data\u0026#34;:null} \u0026#34;/user/1/team\u0026#34;, // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;team\u0026#34;:{\u0026#34;id\u0026#34;:3,\u0026#34;name\u0026#34;:\u0026#34;Apple\u0026#34;}}} \u0026#34;/team/3\u0026#34;, // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;id\u0026#34;:3,\u0026#34;name\u0026#34;:\u0026#34;Apple\u0026#34;}} \u0026#34;/team/5\u0026#34;, // {\u0026#34;code\u0026#34;:400,\u0026#34;msg\u0026#34;:\u0026#34;team not found: 5\u0026#34;,\u0026#34;data\u0026#34;:null} \u0026#34;/team/3/users\u0026#34;, // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;users\u0026#34;:[{\u0026#34;id\u0026#34;:1,\u0026#34;name\u0026#34;:\u0026#34;Alice\u0026#34;,\u0026#34;teamId\u0026#34;:3}]}} \u0026#34;/team/5/users\u0026#34;, // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;Users\u0026#34;:null}} } for _, path := range paths { resp, err := http.Get(\u0026#34;http://localhost:8080\u0026#34; + path) if err != nil { fmt.Println(\u0026#34;req err\u0026#34;, err) continue } data, err := io.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;read resp.Body err\u0026#34;, err) continue } fmt.Println(string(data)) } } 通过对象注册路由 事实上，GoFrame 还有第三种路由注册方法：对象注册，向 (*ghttp.RouterGroup).Bind 传入一个结构体变量，然后 GoFrame 会尝试注册这个结构体上的所有 ReqResFunc 类型的方法。这也是通过反射实现的，核心代码也很简短：\nfunc ObjectHandler(object any) (handles []gin.HandlerFunc) { v := reflect.ValueOf(object) // 如果是结构体, 那么获取这个结构体的指针, 从而遍历到他的所有方法 if v.Kind() == reflect.Struct { newValue := reflect.New(v.Type()) newValue.Elem().Set(v) v = newValue } if v.Kind() != reflect.Pointer { panic(\u0026#34;v.Kind() must be reflect.Pointer\u0026#34;) } for i := 0; i \u0026lt; v.NumMethod(); i++ { fn := v.Method(i) // 所有方法都必须为 ReqResFunc 类型 handles = append(handles, ReqResHandle(fn.Interface())) } return handles } 但是通过对象注册路由有个缺点，难以为 HandlerFunc 绑定 path 和 method。\n已知的解决方式：\nGoFrame 是在 Req（第二个请求参数）里写 go tag，有兴趣的读者，可以查看「文档：规范参数结构」。 iris 要求方法名（函数名）的格式为：请求方法+请求路径，如 GetHelloWorld 对应 GET: /hello/world，示例：examples/mvc/hello-world/main.go 笔者也做了简单的实现：gee/web/day10/handle/handle_test.go，这里就不再赘述了。\n","date":"2023-12-22T15:43:59+08:00","permalink":"https://niluan304.github.io/p/gee-web-day10-%E9%80%9A%E8%BF%87%E5%8F%8D%E5%B0%84%E6%9E%84%E9%80%A0%E8%A7%84%E8%8C%83%E8%B7%AF%E7%94%B1/","title":"gee-web-day10 通过反射构造规范路由"},{"content":" 源代码/数据集已上传到：GitHub - follow gee to learn go\n经过分层处理后，项目布局有了很大改善，但是仍然存在问题。\ncontroller 层的错误处理代码特别繁琐，有太多的：ctx.JSON(http.StatusOK, Response{400, err.Error(), nil}) controller 层只支持 Gin 框架，更不支持其他协议 让调用者帮忙反序列化 观察 controller 层可以得出一个结论：controller 的需求其实很简单：反序列化为 service 层所需要 go 类型，并在 err != nil 时做控制的流转。\n那么该怎么实现呢？这其实并不难。说到反序列化，笔者相信各位都非常熟悉标准库的 json.Unmarshal(data []byte, v any) error，json.Unmarshal 要求传入 JSON 编码的数据源和接收变量的指针，反序列化需要两个最基本的源：数据源和接收源。如果数据源是 r io.Reader类型，还可以直接使用标准库装好的方法：\ndec := json.NewDecoder(r) err := dec.Decode(point) 笔者提及 func (dec *Decoder) Decode(v any) error 有什么用呢？回顾一下 day8 的 controller 层代码：\nfunc (c *user) Get(ctx *gin.Context) { var req *service.UserGetReq err := ctx.ShouldBindUri(\u0026amp;req) ... } 很明显接收源是 var req *service.UserGetReq，而 ctx.ShouldBindUri(\u0026amp;req) 与 dec.Decode(point) 高度相似，甚至函数类型都是：func(point any) error。分析一下，对于 *json.Decoder 和 *gin.Context 来说，数据源都被隐藏在结构体内部了，真正关键的，是反序列化的入口函数：ShouldBindUri 和 Decode，因此是可以将 ctx *gin.Context 替换为 decode func(point any) error 的，外部传入这个闭包，controller 层调用闭包，完成反序列化。修改之后的函数签名：\nfunc (c *user) Get( ctx context.Context, // 第一个参数：ctx decode func(point any) (err error), // 第二个参数：用于反序列化的闭包 ) ( data any, // 返回的数据 err error, // 错误处理 ){ var req service.UserGetReq err = decode( \u0026amp;req) // 通过闭包反序列化 req if err != nil { return nil, err } res, err := service.User.Get(ctx, req) if err != nil { return nil, err } return res, nil } 经过改动的 controller 和 web框架彻底解耦了，完全看不到 Gin 框架的代码，毕竟反序列化的工作也并不是 controller 的任务，错误处理和数据返回也变得非常简单，只需要抛给上层处理（要么 return nil, err，要么 return res, nil），解耦之后也为 controller 层兼容多种协议带来了可能。\n不过但也带来了一个问题：这样的函数，该如何注册到 Gin框架里呢？\n统一错误处理和数据返回 All problems in computer science can be solved by another level of indirection.\n计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。\n阐述这部分内容之前，笔者想简单的介绍一下「设计模式」里的「适配器模式」1：\n简单来讲，就是通过接口转换，让两个不兼容的接口，能够一起工作，现实中的经典例子： 和上面的图片类似，修改后的函数类型已经和框架要求的 gin.HandlerFunc 截然不同，但借鉴适配器模式的思想，通过中间函数转化，就可以了：\n// ./handle/handle.go // 设置为类型，用于优化参数显示 type DecodeFunc = func( ctx context.Context, // 第一个参数：ctx decode func(point any) (err error), // 第二个参数：用于反序列化的闭包 ) ( data any, // 返回的数据 err error, // 错误处理 ) func Handle(decode DecodeFunc) gin.HandlerFunc { return func(c *gin.Context) { data, err := decode(c, func(point any) (err error) { // 实现反序列化 return c.ShouldBind(point) }) if err != nil { c.JSON(http.StatusOK, Response{Code: 400, Msg: err.Error(), Data: nil}) return } c.JSON(http.StatusOK, Response{200, \u0026#34;\u0026#34;, data}) } } 新的函数作为「适配器」，也会被其他路由调用，也不是业务相关的内容，不适合放到 internal 包，应当放到新的包（文件夹）里，笔者将之保存至 /handle/handle.go。\n相应地，路由注册也有些变化：\nfunc main() { r := gin.Default() { user := r.Group(\u0026#34;/user\u0026#34;) user.GET(\u0026#34;/\u0026#34;, handle.Handle(controller.User.Get)) user.POST(\u0026#34;/\u0026#34;, handle.Handle(controller.User.Add)) } r.Run() // listen and serve on 0.0.0.0:8080 (for windows \u0026#34;localhost:8080\u0026#34;) } 对比 day8 的注册模式：\nuser.GET(\u0026#34;/\u0026#34;, controller.User.Get) // 函数签名：func (c *user) Get(ctx *gin.Context) user.POST(\u0026#34;/\u0026#34;, controller.User.Add) // 函数签名：func (c *user) Add(ctx *gin.Context) 虽然注册路由时，必须得借用 handle.Handle 才能转化为 gin.HandlerFunc，但是可以不用在 controller 层里写：\nc.JSON(http.StatusOK, Response{Code: 400, Msg: err.Error(), Data: nil}) c.JSON(http.StatusOK, Response{200, \u0026#34;\u0026#34;, data}) 至此，我们就完成了错误处理和数据返回的统一。\n小结 本章节主要做了两件事：\ncontroller 层通过传入 decode 闭包，调用闭包实现反序列化出 service 层所需数据，也完成了 controller 与框架的解耦，日后可以兼容其他框架（如 echo）和其他协议（如 rpc）。 借鉴适配器模式，将 DecodeFunc 函数转化为框架所需要的类型，并实现错误处理和数据返回的统一。 运行结果也没有变化：\nfunc client() { time.Sleep(time.Second) // 等待路由注册 reqs := []func(host string) (*http.Response, error){ func(host string) (*http.Response, error) { return http.Get(host + \u0026#34;/user?name=Carol\u0026#34;) }, func(host string) (*http.Response, error) { return http.Get(host + \u0026#34;/user?name=Bob\u0026#34;) }, func(host string) (*http.Response, error) { return http.Post(host+\u0026#34;/user\u0026#34;, \u0026#34;application/json\u0026#34;, bytes.NewBufferString(`{\u0026#34;name\u0026#34;:\u0026#34;Carol\u0026#34;,\u0026#34;age\u0026#34;:44,\u0026#34;job\u0026#34;:\u0026#34;worker\u0026#34;}`)) }, func(host string) (*http.Response, error) { return http.Get(host + \u0026#34;/user?name=Carol\u0026#34;) }, } for _, req := range reqs { resp, err := req(\u0026#34;http://localhost:8080\u0026#34;) if err != nil { fmt.Println(\u0026#34;req err\u0026#34;, err) } data, err := io.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;read resp.Body err\u0026#34;, err) } fmt.Println(string(data)) } // Output: // // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:null} // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;Bob\u0026#34;,\u0026#34;age\u0026#34;:30,\u0026#34;job\u0026#34;:\u0026#34;driver\u0026#34;}} // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:null} // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;Carol\u0026#34;,\u0026#34;age\u0026#34;:44,\u0026#34;job\u0026#34;:\u0026#34;worker\u0026#34;}} } 适配器模式\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-12-21T18:15:11+08:00","permalink":"https://niluan304.github.io/p/gee-web-day9-%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E8%A7%A3%E8%80%A6/","title":"gee-web-day9 反序列化与解耦"},{"content":" 源代码/数据集已上传到：GitHub - follow gee to learn go\n什么是请求分层流转 在阐述为什么需要分层设计之前，笔者想先介绍一下分层流转1：\n分层之后，可以让每一层的专注于一类事，这类似于设计模式里单一职责的思想，可以提高项目的可维护性，与接口的可复用性，从而实现低耦合高内聚。计算机网络中的「TCP/IP 四层模式」就是非常典型的分层，实现从 HTTP 到 HTTPS 的升级，只需要在 HTTP 协议与 TCP 中加了一层 TLS，其他层的协议与应用不需要做任何改动，这就是计算机网络模型低耦合高内聚的表现。\n代码纠缠的困境 这里有一份简单的 CURD 代码，只有 *user.Get、*team.Get 两个接口，和对应的数据库表 UserTable、TeamTable，功能也很简单，根据表主键，获取对应的行数据：\n// ./internal/api.go type Response struct { Code int `json:\u0026#34;code\u0026#34;` // 业务代码，200 表示 OK，其他表示错误 Msg string `json:\u0026#34;msg\u0026#34;` // 错误消息 Data any `json:\u0026#34;data\u0026#34;` // 返回的数据 } const ( CodeOK = 200 CodeBadRequest = 400 ) type user struct{} var User = \u0026amp;user{} func (c *user) Get(ctx *gin.Context) { var req *struct { Id int `uri:\u0026#34;id\u0026#34;` } err := ctx.ShouldBindUri(\u0026amp;req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } i := slices.IndexFunc(db.Users, func(row db.User) bool { return row.Id == req.Id }) if i == -1 { // 数据库未找到数据 ctx.JSON(http.StatusOK, Response{CodeBadRequest, fmt.Sprintf(\u0026#34;user not found: %d\u0026#34;, req.Id), nil}) return } // 返回数据库内容 row := db.Users[i] // Users 只是一个切片 []User，用于充当数据库表 ctx.JSON(http.StatusOK, Response{CodeOK, \u0026#34;\u0026#34;, row}) return } type team struct{} var Team = \u0026amp;team{} func (c *team) Get(ctx *gin.Context) { var req *struct { Id int `uri:\u0026#34;id\u0026#34;` } err := ctx.ShouldBindUri(\u0026amp;req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } // 查询数据 i := slices.IndexFunc(db.Teams, func(row db.Team) bool { return row.Id == req.Id }) if i == -1 { // 数据库未找到数据 ctx.JSON(http.StatusOK, Response{CodeBadRequest, fmt.Sprintf(\u0026#34;team not found: %d\u0026#34;, req.Id), nil}) return } // 返回数据库内容 row := db.Teams[i] // Teams 只是一个切片 []Team，用于充当数据库表 ctx.JSON(http.StatusOK, Response{CodeOK, \u0026#34;\u0026#34;, row}) return } 代码很简单，没什么问题，但假如随着项目的进展，需要新增一个接口：通过 userId 获取用户信息和用户所在 Team 的信息。\n返回的数据格式：\ntype UserWithTeam struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Team struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` } `json:\u0026#34;team\u0026#34;` } 这时候理想的处理办法：\n根据 userId 通过 *user.Get 获取到用户信息和 teamId 根据 teamId 通过 *team.Get 获取用户所在 Team 的信息 流程看起来只需要复用先用的接口，就可以实现需求了，比如这样：\nfunc (c *user) GetWithTeam(ctx *gin.Context) { c.Get(ctx) Team.Get(ctx) } 如果仅仅是这样的执行顺序，很明显是错误的，用户端通过路由会得到\u0026quot;粘包的 json\u0026quot;：\n{ \u0026#34;code\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;Id\u0026#34;: 1, \u0026#34;Name\u0026#34;: \u0026#34;Alice\u0026#34;, \u0026#34;TeamId\u0026#34;: 1 } }{ \u0026#34;code\u0026#34;: 400, \u0026#34;msg\u0026#34;: \u0026#34;team not found: 1\u0026#34;, \u0026#34;data\u0026#34;: null } 分析一下原因，\n首先 *gin.Context 通过路由接收到的数据，只有 userId 这个数据，并不包含 teamId，而需要的 teamId 在 *user.Get 接口内部直接写到了 (*gin.Context).JSON 中。 即便有办法获取传入 (*gin.Context).JSON 的数据，还需要改造 *gin.Context，让 *team.Get 也能获取到正确的 teamId，但是修改 *gin.Context 内部数据是很危险的一件事，稍有不慎，就可能跌落悬崖。 如果 *user.Get 和 *team.Get 的设计是传入 id，返回对应信息，那么就可以轻松实现新接口，还能规避修改 *gin.Context，比如这样：\nfunc GetWithTeam(ctx *gin.Context) { user := User.Get(id) team := Team.Get(user.TeamId) // 组装数据，写入返回 // ... } 这其实就运用到计算机网络模型里经典的分层思想，将共同属性的分到同一层，通过上下层的「封包」和「解包」实现解耦。现在比较流行的纯后端 API 模块一般采用下述划分方法2\nController，与上述类似，服务入口，负责处理路由，参数校验，请求转发。 Logic/Service，逻辑（服务）层，一般是业务逻辑的入口，可以认为从这里开始，所有的请求参数一定是合法的。业务逻辑和业务流程也都在这一层中。常见的设计中会将该层称为 Business Rules。 DAO/Repository，这一层主要负责和数据、存储打交道。将下层存储以更简单的函数、接口形式暴露给 Logic 层来使用。负责数据的持久化工作。 分层设计 先介绍下分层后的目录结构：\n. |-- go.mod |-- go.sum |-- internal | |-- controller | | `-- controller.go | `-- service | |-- service.go | `-- service_model.go `-- main.go 当业务代码都放到了 service 层时，这一层的代码互相调用是不会被 controller 层影响的，这也实现了 Gin 框架与业务代码的解耦。\ncontroller 层的主要代码：\n// ./internal/controller/controller.go func (c *user) Get(ctx *gin.Context) { var req *service.UserGetReq err := ctx.ShouldBindUri(\u0026amp;req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } res, err := service.User.Get(ctx, req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } // 填写响应内容 ctx.JSON(http.StatusOK, Response{CodeOK, \u0026#34;\u0026#34;, res}) return } func (c *team) Get(ctx *gin.Context) { var req *service.TeamGetReq err := ctx.ShouldBindUri(\u0026amp;req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } res, err := service.Team.Get(ctx, req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } // 填写响应内容 ctx.JSON(http.StatusOK, Response{CodeOK, \u0026#34;\u0026#34;, res}) return } service 层的主要代码：\n// ./internal/service/service.go func (s *user) Get(ctx context.Context, req *UserGetReq) (res *UserGetRes, err error) { // 查询数据 i := slices.IndexFunc(db.Users, func(row db.User) bool { return row.Id == req.Id }) if i == -1 { // 数据库未找到数据 return nil, fmt.Errorf(\u0026#34;user not found: %d\u0026#34;, req.Id) } // 返回数据库内容 row := db.Users[i] // Users 只是一个切片 []User，用于充当数据库表 return \u0026amp;UserGetRes{Id: row.Id, Name: row.Name, TeamId: row.TeamId}, nil } func (s *team) Get(ctx context.Context, req *TeamGetReq) (res *TeamGetRes, err error) { // 查询数据 i := slices.IndexFunc(db.Teams, func(row db.Team) bool { return row.Id == req.Id }) if i == -1 { // 数据库未找到数据 return nil, fmt.Errorf(\u0026#34;team not found: %d\u0026#34;, req.Id) } // 返回数据库内容 row := db.Teams[i] // Teams 只是一个切片 []Team，用于充当数据库表 return \u0026amp;TeamGetRes{Id: row.Id, Name: row.Name}, nil } 这时候，再来实现一下，新增一个接口：通过 userId 获取用户信息和用户所在 Team 的信息。\nfunc (c *user) GetWithTeam(ctx *gin.Context) { var req *service.UserGetReq err := ctx.ShouldBindUri(\u0026amp;req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } userRes, err := service.User.Get(ctx, req) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } teamRes, err := service.Team.Get(ctx, \u0026amp;service.TeamGetReq{Id: userRes.TeamId}) if err != nil { ctx.JSON(http.StatusOK, Response{CodeBadRequest, err.Error(), nil}) return } type UserWithTeam struct { Id int `json:\u0026#34;id\u0026#34;` Name string `json:\u0026#34;name\u0026#34;` Team service.TeamGetRes `json:\u0026#34;team\u0026#34;` } // 填写响应内容 ctx.JSON(http.StatusOK, Response{CodeOK, \u0026#34;\u0026#34;, UserWithTeam{ Id: userRes.Id, Name: userRes.Name, Team: *teamRes, }}) return } 分层后的总代码行数有所增加，整个项目的布局变得更清晰了，业务代码也不会受到 web框架的干扰，可以集中处理业务。而且业务层的函数签名具有可读性了，调用 service 层的方法时，就可以知道所需要的参数，以及返回的值。不过有些读者可能会有疑问，为什么 service 层方法的第一个参数都是 ctx context.Context，即便代码中未必使用，这算是 go 语言在 web 开发中的特色（也可能是技术债），用于并发控制和上下文信息传递的，有兴趣可以自行了解下。\n但是在 controller 层有太多的 (*gin.Context).JSON()，也就是处理接口的响应，变得异常繁琐，为了解决这一点，笔者将在下一节阐述如何在框架中实现统一错误处理和数据返回。\n小结 本章节介绍下如何通过「分层设计」将一个大问题，转化为若干的分工明确的小问题，实现业务代码与 web框架解耦，提高系统的拓展性和可维护性，从而实现高内聚低耦合。\n注意：分层设计也会导致一个问题：新增一个业务接口时，需要改动的文件也会变多，不过这可以通过脚本生成代码缓解。 最后让我们来看看程序的运行结果：\nfunc client() { time.Sleep(time.Second) // 等待路由注册 reqs := []func(host string) (*http.Response, error){ func(host string) (*http.Response, error) { return http.Get(host + \u0026#34;/user?name=Carol\u0026#34;) }, func(host string) (*http.Response, error) { return http.Get(host + \u0026#34;/user?name=Bob\u0026#34;) }, func(host string) (*http.Response, error) { return http.Post(host+\u0026#34;/user\u0026#34;, \u0026#34;application/json\u0026#34;, bytes.NewBufferString(`{\u0026#34;name\u0026#34;:\u0026#34;Carol\u0026#34;,\u0026#34;age\u0026#34;:44,\u0026#34;job\u0026#34;:\u0026#34;worker\u0026#34;}`)) }, func(host string) (*http.Response, error) { return http.Get(host + \u0026#34;/user?name=Carol\u0026#34;) }, } for _, req := range reqs { resp, err := req(\u0026#34;http://localhost:8080\u0026#34;) if err != nil { fmt.Println(\u0026#34;req err\u0026#34;, err) } data, err := io.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;read resp.Body err\u0026#34;, err) } fmt.Println(string(data)) } // Output: // // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:null} // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;Bob\u0026#34;,\u0026#34;age\u0026#34;:30,\u0026#34;job\u0026#34;:\u0026#34;driver\u0026#34;}} // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:null} // {\u0026#34;code\u0026#34;:200,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;Carol\u0026#34;,\u0026#34;age\u0026#34;:44,\u0026#34;job\u0026#34;:\u0026#34;worker\u0026#34;}} } 工程目录设计🔥 - GoFrame (ZH)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n大型Web项目分层 - Go语言高级编程：\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2023-12-20T13:49:08+08:00","permalink":"https://niluan304.github.io/p/gee-web-day8-%E5%88%86%E5%B1%82%E8%AE%BE%E8%AE%A1%E7%9A%84%E5%BF%85%E8%A6%81%E6%80%A7/","title":"gee-web-day8 分层设计的必要性"},{"content":"在国内执行 git clone https://github.com/golang/go.git 操作，又慢又不稳定，搜索后发现可以使用代理这个问题。\n准备工作 首先，你需要准备好代理工具，一般的代理工具都有 Sock5 和 HTTP 两种代理方式。\n常见的代理软件使用的端口有：7890, 1080，下文的 {port} 参数都需要修改为对应的端口号。\n笔者会按照 Windows 和 类 Unix 系统介绍为 git 设置代理的方法，由于相似处很多，请按需查看。\nWindows 下 为 HTTP 协议设置代理 在 GitHub上，通过第一种方式克隆仓库，这里走的就是 HTTP 协议，修改起来也很简单：\n命令行设置 通过代理软件 HTTP 的端口 在终端中执行以下命令： # {port} 修改为代理软件的端口 git config --global https.https://github.com.proxy https://127.0.0.1:{port} 通过代理软件 Sock5 的端口 在终端中执行以下命令： # {port} 修改为代理软件的端口 git config --global https.https://github.com.proxy socks5://127.0.0.1:{port} 可以发现，两者的命令极其相似，格式都为：\ngit config --global https.https://github.com.proxy {protocol}://{ip}:{port} 所以，凭个人喜好使用就好。\n另外，如果代理软件并不在本地运行，那么就将 127.0.0.1 修改为代理软件服务器的 ip（需要有访问权限）。\n修改 .gitconfig 文件 如果不喜欢在命令行中操作，也可以直接修改 C:/Users/${your username}/.gitconfig 文件，在文件末尾添加以下内容：\n通过代理软件 HTTP 的端口 [https \u0026#34;https://github.com\u0026#34;] # {port} 修改为代理软件的端口 proxy = https://127.0.0.1:{port} 通过代理软件 Sock5 的端口 [http \u0026#34;https://github.com\u0026#34;] # {port} 修改为代理软件的端口 proxy = socks5://127.0.0.1:{port} 取消代理 通过命令行：\ngit config --global --unset https.https://github.com.proxy 也可以修改 C:/Users/${your username}/.gitconfig 文件，删除或注释 [https \u0026quot;https://github.com\u0026quot;] 区域的内容。\n为 SSH 协议设置代理 在 GitHub上，通过第二种方式克隆仓库，走的就是 SSH 协议：\n修改 .ssh/config 文件 找到 ~/.ssh 目录下的 config 文件（如果没有找到这个文件，那么新建即可）。\n通过代理软件 HTTP 的端口 config 文件末尾添加以下内容： Host github.com Hostname ssh.github.com # git 在 window 下使用的代理软件为 connect # -H为HTTP协议， -S指Socks 5协议 # {port} 修改为代理软件的端口 ProxyCommand connect -H 127.0.0.1:{port} %h %p # 服务对应端口 Port 443 通过代理软件 Sock5 的端口 config 文件末尾添加以下内容： Host github.com Hostname ssh.github.com # git 在 window 下使用的代理软件为 connect # -H为HTTP协议， -S指Socks 5协议 # {port} 修改为代理软件的端口 ProxyCommand connect -S 127.0.0.1:{port} %h %p # 服务对应端口 Port 443 验证 先打开 git bash ，然后执行：\nssh -T git@github.com` 结果类似：\n$ ssh -T git@github.com Hi niluan304! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. 类 Unix 系统 为 HTTP 协议设置代理 在 GitHub上，通过第一种方式克隆仓库，这里走的就是 HTTP 协议，修改起来也很简单：\n命令行设置 通过代理软件 HTTP 的端口 在终端中执行以下命令： # {port} 修改为代理软件的端口 git config --global https.https://github.com.proxy https://127.0.0.1:{port} 通过代理软件 Sock5 的端口 在终端中执行以下命令： # {port} 修改为代理软件的端口 git config --global https.https://github.com.proxy socks5://127.0.0.1:{port} 可以发现，两者的命令极其相似，格式都为：\ngit config --global https.https://github.com.proxy {protocol}://{ip}:{port} 所以，凭个人喜好使用就好。\n另外，如果代理软件并不在本地运行，那么就将 127.0.0.1 修改为代理软件服务器的 ip（需要有访问权限）。\n修改 .gitconfig 文件 如果不喜欢在命令行中操作，也可以直接修改 ~/.gitconfig 文件，在文件末尾添加以下内容：\n通过代理软件 HTTP 的端口 [https \u0026#34;https://github.com\u0026#34;] # {port} 修改为代理软件的端口 proxy = https://127.0.0.1:{port} 通过代理软件 Sock5 的端口 [http \u0026#34;https://github.com\u0026#34;] # {port} 修改为代理软件的端口 proxy = socks5://127.0.0.1:{port} 取消代理 通过命令行：\ngit config --global --unset https.https://github.com.proxy 也可以修改 ~/.gitconfig 文件，删除或注释 [https \u0026quot;https://github.com\u0026quot;] 区域的内容。\n为 SSH 协议设置代理 在 GitHub上，通过第二种方式克隆仓库，走的就是 SSH 协议：\n修改 .ssh/config 文件 找到 ~/.ssh 目录下的 config 文件（如果没有找到这个文件，那么新建即可）。\n通过代理软件 HTTP 的端口 config 文件末尾添加以下内容： Host github.com Hostname ssh.github.com # git 在 Linux 和 Mac 下使用的代理软件为 netcat，简称nc。 # -X 5 指代理协议Socks 5， -X 4 指代理协议Socks 4， -X connect指代理协议Socks HTTP ProxyCommand nc -v -X 127.0.0.1:xxxx %h %p # 服务对应端口 Port 443 通过代理软件 Sock5 的端口 config 文件末尾添加以下内容： Host github.com Hostname ssh.github.com # git 在 Linux 和 Mac 下使用的代理软件为 netcat，简称nc。 # -X 5 指代理协议Socks 5， -X 4 指代理协议Socks 4， -X connect指代理协议Socks HTTP ProxyCommand nc -v -X 5 127.0.0.1:xxxx %h %p # 服务对应端口 Port 443 验证 先打开 git bash ，然后执行：\nssh -T git@github.com 结果类似：\n$ ssh -T git@github.com Hi niluan304! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. 如果遇到错误，可以删除 .ssh 目录中 known_hosts 文件后重试。\n","date":"2023-03-14T18:08:02+08:00","permalink":"https://niluan304.github.io/p/%E4%B8%BA-git-clone-github-%E8%AE%BE%E7%BD%AE-http-%E5%92%8C-ssh-%E4%BB%A3%E7%90%86/","title":"为 git clone github 设置 HTTP 和 SSH 代理"},{"content":"使用 slices.Sort 和 slices.SortFunc 避免 sort.Slices 的坑\nsort.Slices 介绍 sort.Slices 是go 于1.18 版本新增的排序函数，签名如下：\nfunc Slice(x any, less func(i, j int) bool) 使用起来非常简单：\nfunc main() { type Student struct { Name string Age int } students := []Student{ {Name: \u0026#34;Gopher\u0026#34;, Age: 14}, {Name: \u0026#34;Carol\u0026#34;, Age: 10}, {Name: \u0026#34;Alice\u0026#34;, Age: 10}, {Name: \u0026#34;Bob\u0026#34;, Age: 15}, {Name: \u0026#34;Dave\u0026#34;, Age: 12}, } // sort by Age first, Name second sort.Slice(students, func(i, j int) bool { x, y := students[i], students[j] if x.Age != y.Age { return x.Age \u0026lt; y.Age } return x.Name \u0026lt; y.Name }) for _, student := range students { fmt.Printf(\u0026#34;%d %s\\n\u0026#34;, student.Age, student.Name) } } // Output: // 10 Alice // 10 Carol // 12 Dave // 14 Gopher // 15 Bob 闭包的坑 上面的代码中，甚至进行了多字段排序。但如果我们只需要部分排序，代码又该怎么写呢？\n这样对吗？\nfunc SortAfter(nums []int, p int) { // 从p开始排序 sort.Slice(nums[p:], func(i, j int) bool { return nums[i] \u0026lt; nums[j] }) } 咋一看没什么问题，跑下测试用例吧：\nfunc main() { nums := []int{2, 3, 1, 5, 4, 6, 7} tests := []struct { p int want []int }{ {p: 1, want: []int{2, 1, 3, 4, 5, 6, 7}}, {p: 2, want: []int{2, 3, 1, 4, 5, 6, 7}}, {p: 3, want: []int{2, 3, 1, 4, 5, 6, 7}}, } for _, tt := range tests { got := slices.Clone(nums) // 拷贝原始数据，用于测试 SortAfter(got, tt.p) if !reflect.DeepEqual(got, tt.want) { fmt.Printf(\u0026#34;when p: %v ,want: %v, but got: %v\\n\u0026#34;, tt.p, tt.want, got) } } } // Output: // when p: 1 ,want: [2 1 3 4 5 6 7], but got: [2 3 5 6 7 4 1] // when p: 3 ,want: [2 3 1 4 5 6 7], but got: [2 3 1 5 6 4 7] 为什么 p = 1,3 时不对，p = 2 时又是对的呢？ 因为 sort.Slices 接收到的参数是 nums[p:]，less 闭包里的参数 i, j 是在 nums[p:] 的位置，如果直接比较 nums[i] 和nums[j]，那就忽略了 p 偏移的影响，所以实际要比较的元素其实是 nums[i+p] 和 nums[j+p]，那么修复后的函数：\nfunc SortAfter(nums []int, p int) { // 从p开始排序 sort.Slice(nums[p:], func(i, j int) bool { // 这里传入的slice不再是完整的nums，而是nums[p:] return nums[i+p] \u0026lt; nums[j+p] }) } 使用 slices.Sort 优化 手动修正偏移量，可以避免部分排序这个坑一时，但日后依旧有可能因为思维惯性而导致再次踩坑。具体实现也很别扭，也不方便修改。\n好在 go 在 1.21 版本新增了了 slices 这个泛型库，里面包含了很多切片的通用操作，其中的 slices.Sort 和 slices.SortFunc 函数就可以避免上面的坑。\n这两个函数的签名：\nfunc Sort[S ~[]E, E cmp.Ordered](x S) func SortFunc[S ~[]E, E any](x S, cmp func(a, b E) int) 使用方法也很简单，直接传入要排序的部分，如果调用 slices.Sort，还可以省去用手写 less 闭包函数。 最重要的是，按照直觉使用这两个函数就可以避免 sort.Slices 在部分排序时的坑：\nfunc main() { nums := []int{2, 3, 1, 5, 4, 6, 7} tests := []struct { p int want []int }{ {p: 0, want: []int{1, 2, 3, 4, 5, 6, 7}}, {p: 1, want: []int{2, 1, 3, 4, 5, 6, 7}}, {p: 2, want: []int{2, 3, 1, 4, 5, 6, 7}}, {p: 3, want: []int{2, 3, 1, 4, 5, 6, 7}}, } for _, tt := range tests { got := slices.Clone(nums) // 拷贝原始数据，用于测试 slices.Sort(got[tt.p:]) if !reflect.DeepEqual(got, tt.want) { fmt.Printf(\u0026#34;when p: %v ,want: %v, but got: %v\\n\u0026#34;, tt.p, tt.want, got) } } } 而使用 sort.SortFunc，搭配 go 1.22 新增的泛型函数 cmp.Or，可以更轻松的实现多字段排序，这段代码来自 go1.22 标准库 cmp/cmp_test.go：\nfunc main() { type Order struct { Product string Customer string Price float64 } orders := []Order{ {\u0026#34;foo\u0026#34;, \u0026#34;alice\u0026#34;, 1.00}, {\u0026#34;bar\u0026#34;, \u0026#34;bob\u0026#34;, 3.00}, {\u0026#34;baz\u0026#34;, \u0026#34;carol\u0026#34;, 4.00}, {\u0026#34;foo\u0026#34;, \u0026#34;alice\u0026#34;, 2.00}, {\u0026#34;bar\u0026#34;, \u0026#34;carol\u0026#34;, 1.00}, {\u0026#34;foo\u0026#34;, \u0026#34;bob\u0026#34;, 4.00}, } // Sort by customer first, product second, and last by higher price slices.SortFunc(orders, func(a, b Order) int { return cmp.Or( cmp.Compare(a.Customer, b.Customer), cmp.Compare(a.Product, b.Product), cmp.Compare(b.Price, a.Price), ) }) for _, order := range orders { fmt.Printf(\u0026#34;%s %s %.2f\\n\u0026#34;, order.Product, order.Customer, order.Price) } } // Output: // foo alice 2.00 // foo alice 1.00 // bar bob 3.00 // foo bob 4.00 // bar carol 1.00 // baz carol 4.00 其中 cmp.Or 的源码 非常简单，只是用于找出切片中第一个非零的元素：\n// Or returns the first of its arguments that is not equal to the zero value. // If no argument is non-zero, it returns the zero value. func Or[T comparable](vals ...T) T { var zero T for _, val := range vals { if val != zero { return val } } return zero } 可以看到，这样写 less 函数，比手写多个 if 优雅太多了。\n参考资料 golang sort.Slice踩坑记录 - 简书 ","date":"2023-03-11T00:00:00Z","image":"https://niluan304.github.io/p/sort.slice-%E4%B8%8D%E9%80%82%E5%90%88%E9%83%A8%E5%88%86%E6%8E%92%E5%BA%8F/Feng_2024-03-12_10-13-25_huca69348bf10406e412f1d3e0ec3bf9be_11506_120x120_fill_box_smart1_3.png","permalink":"https://niluan304.github.io/p/sort.slice-%E4%B8%8D%E9%80%82%E5%90%88%E9%83%A8%E5%88%86%E6%8E%92%E5%BA%8F/","title":"sort.Slice 不适合部分排序"},{"content":"wsl 常用命令 重启 wsl 尝试重启 wsl，使用命令 wsl --shuntdown 或其他命令，终端被挂起，无反应。\n解决办法：kill LxssManager\n找到 svchost.exe 进程的 pid, 然后在「任务管理器/详细信息」里结束这个进程 echo 寻找 `pid` 的指令： tasklist /svc /fi \u0026#34;imagename eq svchost.exe\u0026#34; | findstr LxssManager PowerShell7 里 kill LxssManager echo 在 `PowerShell7` 里运行（可能需要管理员启动）： Stop-Process -Id $(Get-CimInstance -ClassName Win32_Service -Filter \u0026#34;Name=\u0026#39;LxssManager\u0026#39;\u0026#34;).ProcessId -Force 安装 docker 最简单的办法，大概是安装 Docker Desktop，笔者使用了一段时间，似乎有兼容性问题（可能和笔者同时使用 Hyper-V 安卓模拟器有关系），于是又更换为 Linux 版本的 docker。\n直接运行官方的脚本，即可完成安装：\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo service docker start 但是笔者的机器安装过 Docker Desktop，运行 service docker start 后显示：\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running? 经过排查，发现还需要清理 Docker Desktop 相关的配置。安装过 Docker Desktop，所以 docker 的配置文件 /root/.docker/config.json 含有这个配置项：\n{ \u0026#34;credsStore\u0026#34;: \u0026#34;desktop.exe\u0026#34; } docker 会因为配置了 \u0026quot;credsStore\u0026quot; 字段去运行 \u0026quot;desktop.exe\u0026quot;，而这个程序就是 Docker Desktpo，才导致 docker 无法启动。\n解决办法：\n删除 docker 配置文件里的 \u0026quot;credsStore\u0026quot; 字段。 如果里面的配置不重要，也可以直接删除这个文件：rm /root/.docker/config.json。 ","date":"2023-02-10T10:28:36+08:00","permalink":"https://niluan304.github.io/p/wsl-%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/","title":"Wsl 使用笔记"}]